{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\" align=\"center\"> Projet d'introduction au Machine Learning <br/> Out-Of-Domain PoS Tagging <br/> Présentation des résultats algorithmique</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization...\n",
      "\tPreparing corpus fr.foot.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.gsd.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.sequoia.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.ftb.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.ftb.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.spoken.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.pud.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.spoken.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.natdis.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.partut.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.sequoia.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.gsd.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.sequoia.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.gsd.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.pud.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.ftb.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.partut.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.partut.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.spoken.dev.json...\n",
      "\tDone\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#chargement des corpus en mémoire\n",
    "\n",
    "import dataAnalysis as da\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "da.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistique des corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itère sur chacun des corpus\n",
    "def iterateCorpus(f, printing = True):\n",
    "    for nameCorpus, corpus in da.listeCorpus.items():\n",
    "        if printing:\n",
    "            print(\"corpus : \", nameCorpus)\n",
    "        for typeDS, dataset in corpus.getDataset().items():\n",
    "            if printing:\n",
    "                print(\"ensemble \", typeDS)\n",
    "            f(dataset, nameCorpus, typeDS)\n",
    "\n",
    "# met à jour les données statistiques\n",
    "def updateStat(dataset, nm, tds):\n",
    "    dataset.updateStat()\n",
    "\n",
    "# affiche les statistiques basique\n",
    "\n",
    "\n",
    "def printBasicStat(dataset, nm, tds):\n",
    "    #baseStat.append((nm + \" \" + tds, len(dataset.data), dataset.nbWord, dataset.nbUniqueWords))\n",
    "    print(\"   nombre de phrase : \", len(dataset.data))\n",
    "    print(\"   nombre de mot : \", dataset.nbWord)\n",
    "    print(\"   nombre de mot unique : \", dataset.nbUniqueWords)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# affiche les 10 mots / labels les plus fréquents de chaque corpus\n",
    "def printMostFrequent(dataset, nm, tds):\n",
    "    print()\n",
    "    print(\"10 mots les plus fréquents : \")\n",
    "    print(dataset.mostFrequentWord)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"labels les plus fréquents : \")\n",
    "    print(dataset.mostFrequentLabel)\n",
    "    print()\n",
    "    \n",
    "# affiche les 10 mots les plus ambigu de chaque corpus\n",
    "def printMostAmbiguousWord(dataset, nm, tds):\n",
    "    ambiguousDict, ambiguousWord = dataset.ambiguousWord()\n",
    "    \n",
    "    def sortSecond(val):\n",
    "        return len(val[1])\n",
    "    \n",
    "    ambiguousWord.sort(key = sortSecond, reverse = True)\n",
    "    \n",
    "    print()\n",
    "    print(\"5 mots les plus ambigu : \", ambiguousWord[:5])\n",
    "    print()\n",
    "    \n",
    "iterateCorpus(updateStat, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseStat = []\n",
    "\n",
    "iterateCorpus(printBasicStat)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "#print(tabulate(baseStat, tablefmt=\"latex\", floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterateCorpus(printMostFrequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mot les plus ambigu de chaque corpus\n",
    "\n",
    "iterateCorpus(printMostAmbiguousWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out Of Vocabulary Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul des Out of Vocabulary Words\n",
    "oovLatex = []\n",
    "\n",
    "\n",
    "footTest = da.listeCorpus['foot'].testDataSet\n",
    "natdisTest = da.listeCorpus['natdis'].testDataSet\n",
    "\n",
    "\n",
    "for nameCorpus, corpus in da.listeCorpus.items():\n",
    "    if corpus.trainExist:\n",
    "        oovResult = corpus.computeCorpusOOV()\n",
    "        oovResultFoot = corpus.computeOOV(footTest)\n",
    "        oovResultnatdis = corpus.computeOOV(natdisTest)\n",
    "        print(nameCorpus, \" : \")\n",
    "        print(\"     Pourcentage de l'oov entre train et test : \", oovResult[0])\n",
    "        print(\"     Pourcentage de l'oov entre train et dev : \", oovResult[1])\n",
    "        print(\"     Pourcentage de l'oov entre train et footTest : \", oovResultFoot)\n",
    "        print(\"     Pourcentage de l'oov entre train et natdisTest : \", oovResultnatdis)\n",
    "        latexRows = (nameCorpus, oovResult[0], oovResult[1], oovResultFoot, oovResultnatdis)\n",
    "        oovLatex.append(latexRows)\n",
    "\n",
    "print(tabulate(oovLatex, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divergence de Kullback-Leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul des divergence de KullBack-Leibler\n",
    "\n",
    "latexDKL = []\n",
    "\n",
    "for nameCorpus, corpus in da.listeCorpus.items():\n",
    "    if corpus.trainExist:\n",
    "        print(nameCorpus + \" : \")\n",
    "        DKLResult = corpus.computeCorpusKLDivergence()\n",
    "        DKLFootresult = corpus.computeKLDivergence(footTest)\n",
    "        DKLnatdisResult = corpus.computeKLDivergence(natdisTest)\n",
    "        print(\"     Dkl(test||train) = \", DKLResult)\n",
    "        print(\"     Dkl(footTest||train) = \", DKLFootresult)\n",
    "        print(\"     Dkl(natdisTest||train) = \", DKLnatdisResult)\n",
    "        latexDKL.append( (nameCorpus, DKLResult, DKLFootresult, DKLnatdisResult) )\n",
    "        \n",
    "        \n",
    "print(tabulate(latexDKL, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latexPerplexity = []\n",
    "\n",
    "print(\"                         train,                   test,              dev\")\n",
    "for nameCorpus, corpus in da.listeCorpus.items():\n",
    "    print(nameCorpus, \" : \")\n",
    "    pp_res = corpus.computePerplexityCorpus()\n",
    "    print(\"     perplexity : \", pp_res)\n",
    "    latexRow = []\n",
    "    latexRow.append(nameCorpus)\n",
    "    if type(pp_res) == tuple:\n",
    "        for i in pp_res:\n",
    "            latexRow.append(i)\n",
    "    else:\n",
    "        latexRow.append(pp_res)\n",
    "    latexPerplexity.append( latexRow )\n",
    "    \n",
    "print(tabulate(latexPerplexity, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "## Decision Tree Classifier\n",
    "\n",
    "### Validation croisée detection des meilleurs hyper-paramètre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modelAnalysis as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestTree, bestParam, scoreDev = ma.analyzeDecisionTree(\"partut\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for namedataset, _ in da.listeCorpus.items():\n",
    "    if namedataset not in [\"gsd\", \"ftb\"]:\n",
    "        ma.analyzeDecisionTree(namedataset, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse du changement de contexte avec les meilleurs hyper-paramètre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DecisionTreeClassifier as dtree\n",
    "import features as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "footTest = da.listeCorpus[\"foot\"].testDataSet\n",
    "natdisTest = da.listeCorpus[\"natdis\"].testDataSet\n",
    "\n",
    "Xfoot, Yfoot = ft.buildFeature(footTest)\n",
    "Xnatdis, Ynatdis = ft.buildFeature(natdisTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4364528516472975648                    0                    1 ...\n",
      "  -7126212076657906499 -4364528516472975648 -4364528516472975648]\n",
      " [ 8990308659784620168                    1                    0 ...\n",
      "  -2983421050434475244  6799397574740313146  1205232641019572372]\n",
      " [-2676409561119520413                    2                    0 ...\n",
      "   7408072461626868408 -2676409561119520413 -2676409561119520413]\n",
      " ...\n",
      " [-7625737575186421936                    6                    0 ...\n",
      "   7408072461626868408 -5211186401583140660 -1804067917534604222]\n",
      " [ 7695207225674132950                    7                    0 ...\n",
      "   7695207225674132950  7695207225674132950  7695207225674132950]\n",
      " [-4165234783850999894                    8                    0 ...\n",
      "  -4165234783850999894 -4165234783850999894 -4165234783850999894]]\n",
      "['DET' 'NOUN' 'ADP' ... 'ADJ' 'PUNCT' 'PUNCT']\n",
      "[[-4364528516472975648                    0                    1 ...\n",
      "  -7126212076657906499 -4364528516472975648 -4364528516472975648]\n",
      " [ 8990308659784620168                    1                    0 ...\n",
      "  -2983421050434475244  6799397574740313146  1205232641019572372]\n",
      " [-2676409561119520413                    2                    0 ...\n",
      "   7408072461626868408 -2676409561119520413 -2676409561119520413]\n",
      " ...\n",
      " [-7625737575186421936                    6                    0 ...\n",
      "   7408072461626868408 -5211186401583140660 -1804067917534604222]\n",
      " [ 7695207225674132950                    7                    0 ...\n",
      "   7695207225674132950  7695207225674132950  7695207225674132950]\n",
      " [-4165234783850999894                    8                    0 ...\n",
      "  -4165234783850999894 -4165234783850999894 -4165234783850999894]]\n",
      "\n",
      "[1 0 2 ... 5 3 3]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-964dc76a5eed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdecisionTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecisionTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mscoreFoot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_foot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecisionTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXfoot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYfoot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Informatique_et_Programmation/Intelligence Artificielle/M1_Intro_machine_learning/Projet/src/DecisionTreeClassifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredictSingleWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Informatique_et_Programmation/Intelligence Artificielle/M1_Intro_machine_learning/Projet/src/DecisionTreeClassifier.py\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(X, Y, max_depth)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# ou que l'ensemble des labels ne contient qu'un seul type de labels,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;31m# (cela signifie que l'arbre à déjà réussi à discriminer ce labels pour cette branche)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "corpus = [\"partut\", \"pud\", \"sequoia\", \"spoken\"]\n",
    "bestParam = [(15, \"entropy\", \"mean\"), (16, \"entropy\", \"mean\"), (17, \"entropy\", \"median\"), (15, \"entropy\", \"mean\")]\n",
    "\n",
    "for nameDataset, (max_depth, split_criterion, gen_test) in zip(corpus, bestParam):\n",
    "    train = da.listeCorpus[nameDataset].trainDataSet\n",
    "    Xtrain, Ytrain = ft.buildFeature(train)\n",
    "\n",
    "    \n",
    "    decisionTree = dtree.DecisionTreeClassifier(Xtrain, Ytrain, max_depth, split_criterion, gen_test)\n",
    "    tree = decisionTree.fit()\n",
    "    \n",
    "    scoreFoot, cm_foot = decisionTree.modelScore(tree, Xfoot, Yfoot)\n",
    "    scoreNatdis, cm_natdis = decisionTree.modelScore(tree, Xnatdis, Ynatdis)\n",
    "    \n",
    "    cm_foot_fig = showConfusionMatrix(\n",
    "            cm_foot, decisionTree.classLabel.keys(), title=\"confusion matrix between \" + nameDataset + \" train and foot test\")\n",
    "    \n",
    "    cm_natdis_fig = showConfusionMatrix(\n",
    "            cm_foot, decisionTree.classLabel.keys(), title=\"confusion matrix between \" + nameDataset + \" train and natdis test\")\n",
    "    \n",
    "    cm_foot_fig.savefig(\"../results/decisionTree/confusion_matrix_foot_\" + nameDataset)\n",
    "    cm_natdis_fig.savefig(\"../results/decisionTree/confusion_matrix_natdis_\" + nameDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partutTrain = da.listeCorpus[\"partut\"].trainDataSet\n",
    "bestParamPartut = (15, \"entropy\", \"mean\")\n",
    "\n",
    "pudTrain = da.listeCorpus[\"pud\"].trainDataSet\n",
    "bestParamPud = (16, \"entropy\", \"mean\")\n",
    "\n",
    "sequoiaTrain = da.listeCorpus[\"sequoia\"].trainDataSet\n",
    "bestParamSequoia = (17, \"entropy\", \"median\")\n",
    "\n",
    "spokenTrain = da.listeCorpus[\"spoken\"].trainDataSet\n",
    "bestParamSpoken = (15, \"entropy\", \"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NaiveBayesClassifier as naivebc\n",
    "\n",
    "naiveBC = naivebc.NaiveBayesClassifier(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naiveBC.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, cm = naiveBC.modelScore(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.showConfusionMatrix(cm, decisionTree.classLabel.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtrain, Ytrain = ft.buildFeature(trainSet, lambda x:x)\n",
    "Xtest, Ytest = ft.buildFeature(testSet, lambda x:x)\n",
    "\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(trainSet, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
