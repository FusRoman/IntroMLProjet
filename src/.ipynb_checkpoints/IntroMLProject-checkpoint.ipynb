{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\" align=\"center\"> Projet d'introduction au Machine Learning <br/> Out-Of-Domain PoS Tagging <br/> Présentation des résultats algorithmique</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization...\n",
      "\tPreparing corpus fr.foot.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.gsd.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.sequoia.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.ftb.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.ftb.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.spoken.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.pud.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.spoken.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.natdis.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.partut.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.sequoia.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.gsd.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.sequoia.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.gsd.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.pud.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.ftb.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.partut.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.partut.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.spoken.dev.json...\n",
      "\tDone\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#chargement des corpus en mémoire\n",
    "\n",
    "import dataAnalysis as da\n",
    "import pandas as pds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pds.set_option('display.max_colwidth', -1)\n",
    "da.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistique des corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itère sur chacun des corpus\n",
    "def iterateCorpus(f, printing = True):\n",
    "    for nameCorpus, corpus in da.listeCorpus.items():\n",
    "        if printing:\n",
    "            print(\"corpus : \", nameCorpus)\n",
    "        for typeDS, dataset in corpus.getDataset().items():\n",
    "            if printing:\n",
    "                print(\"ensemble \", typeDS)\n",
    "            f(dataset, nameCorpus, typeDS)\n",
    "\n",
    "# met à jour les données statistiques\n",
    "def updateStat(dataset, nm, tds):\n",
    "    dataset.updateStat()\n",
    "\n",
    "# affiche les statistiques basique\n",
    "\n",
    "\n",
    "def printBasicStat(dataset, nm, tds):\n",
    "    #baseStat.append((nm + \" \" + tds, len(dataset.data), dataset.nbWord, dataset.nbUniqueWords))\n",
    "    print(\"   nombre de phrase : \", len(dataset.data))\n",
    "    print(\"   nombre de mot : \", dataset.nbWord)\n",
    "    print(\"   nombre de mot unique : \", dataset.nbUniqueWords)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# affiche les 10 mots / labels les plus fréquents de chaque corpus\n",
    "def printMostFrequent(dataset, nm, tds):\n",
    "    print()\n",
    "    print(\"10 mots les plus fréquents : \")\n",
    "    print(dataset.mostFrequentWord)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"labels les plus fréquents : \")\n",
    "    print(dataset.mostFrequentLabel)\n",
    "    print()\n",
    "    \n",
    "# affiche les 10 mots les plus ambigu de chaque corpus\n",
    "def printMostAmbiguousWord(dataset, nm, tds):\n",
    "    ambiguousDict, ambiguousWord = dataset.ambiguousWord()\n",
    "    \n",
    "    def sortSecond(val):\n",
    "        return len(val[1])\n",
    "    \n",
    "    ambiguousWord.sort(key = sortSecond, reverse = True)\n",
    "    \n",
    "    print()\n",
    "    print(\"5 mots les plus ambigu : \", ambiguousWord[:5])\n",
    "    print()\n",
    "    \n",
    "iterateCorpus(updateStat, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseStat = []\n",
    "\n",
    "iterateCorpus(printBasicStat)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "#print(tabulate(baseStat, tablefmt=\"latex\", floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterateCorpus(printMostFrequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mot les plus ambigu de chaque corpus\n",
    "\n",
    "iterateCorpus(printMostAmbiguousWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out Of Vocabulary Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul des Out of Vocabulary Words\n",
    "oovLatex = []\n",
    "\n",
    "\n",
    "footTest = da.listeCorpus['foot'].testDataSet\n",
    "natdisTest = da.listeCorpus['natdis'].testDataSet\n",
    "\n",
    "\n",
    "for nameCorpus, corpus in da.listeCorpus.items():\n",
    "    if corpus.trainExist:\n",
    "        oovResult = corpus.computeCorpusOOV()\n",
    "        oovResultFoot = corpus.computeOOV(footTest)\n",
    "        oovResultnatdis = corpus.computeOOV(natdisTest)\n",
    "        print(nameCorpus, \" : \")\n",
    "        print(\"     Pourcentage de l'oov entre train et test : \", oovResult[0])\n",
    "        print(\"     Pourcentage de l'oov entre train et dev : \", oovResult[1])\n",
    "        print(\"     Pourcentage de l'oov entre train et footTest : \", oovResultFoot)\n",
    "        print(\"     Pourcentage de l'oov entre train et natdisTest : \", oovResultnatdis)\n",
    "        latexRows = (nameCorpus, oovResult[0], oovResult[1], oovResultFoot, oovResultnatdis)\n",
    "        oovLatex.append(latexRows)\n",
    "\n",
    "print(tabulate(oovLatex, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divergence de Kullback-Leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul des divergence de KullBack-Leibler\n",
    "\n",
    "latexDKL = []\n",
    "\n",
    "for nameCorpus, corpus in da.listeCorpus.items():\n",
    "    if corpus.trainExist:\n",
    "        print(nameCorpus + \" : \")\n",
    "        DKLResult = corpus.computeCorpusKLDivergence()\n",
    "        DKLFootresult = corpus.computeKLDivergence(footTest)\n",
    "        DKLnatdisResult = corpus.computeKLDivergence(natdisTest)\n",
    "        print(\"     Dkl(test||train) = \", DKLResult)\n",
    "        print(\"     Dkl(footTest||train) = \", DKLFootresult)\n",
    "        print(\"     Dkl(natdisTest||train) = \", DKLnatdisResult)\n",
    "        latexDKL.append( (nameCorpus, DKLResult, DKLFootresult, DKLnatdisResult) )\n",
    "        \n",
    "        \n",
    "print(tabulate(latexDKL, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latexPerplexity = []\n",
    "\n",
    "print(\"                         train,                   test,              dev\")\n",
    "for nameCorpus, corpus in da.listeCorpus.items():\n",
    "    print(nameCorpus, \" : \")\n",
    "    pp_res = corpus.computePerplexityCorpus()\n",
    "    print(\"     perplexity : \", pp_res)\n",
    "    latexRow = []\n",
    "    latexRow.append(nameCorpus)\n",
    "    if type(pp_res) == tuple:\n",
    "        for i in pp_res:\n",
    "            latexRow.append(i)\n",
    "    else:\n",
    "        latexRow.append(pp_res)\n",
    "    latexPerplexity.append( latexRow )\n",
    "    \n",
    "print(tabulate(latexPerplexity, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$log(A * B * C) = log(A) + log(B) + log(C)$\n",
    "\n",
    "$log(\\Pi^{N}_{i=1}P(w_i | w_{i-2}, w_{i-1})) = \\Sigma^N_{i=1}log(P(w_i | w_{i-2}, w_{i-1}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import DecisionTreeClassifier as dtree\n",
    "\n",
    "trainPartut, testPartut = da.listeCorpus[\"partut\"].trainDataSet, da.listeCorpus[\"partut\"].testDataSet\n",
    "\n",
    "Xtrain, Ytrain = dtree.buildFeature(trainPartut)\n",
    "Xtest, Ytest = dtree.buildFeature(testPartut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "bestScore = -1\n",
    "\n",
    "listScoreTrain = []\n",
    "listScoreTest = []\n",
    "bestTree = None\n",
    "\n",
    "for i in range(35):\n",
    "    decisionTreePartut = dtree.DecisionTreeClassifier(Xtrain, Ytrain, max_depth = i)\n",
    "    past = time.time()\n",
    "    tree = decisionTreePartut.fit()\n",
    "    print(\"training time : \", time.time() - past)\n",
    "    scoreTest = decisionTreePartut.modelScore(tree, Xtest, Ytest)\n",
    "    scoreTrain = decisionTreePartut.modelScore(tree, Xtrain, Ytrain)\n",
    "    listScoreTrain.append(scoreTrain)\n",
    "    listScoreTest.append(scoreTest)\n",
    "    if scoreTest > bestScore:\n",
    "        bestScore = scoreTest\n",
    "        bestTree = tree\n",
    "        print(\"Max depth : \", i, \"score on train : \", scoreTrain, \"  Actual score on test : \", scoreTest, \" Highscore !!\")\n",
    "    else:\n",
    "        print(\"Max depth : \", i, \"score on train : \", scoreTrain, \"  Actual score on test : \", scoreTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(35), listScoreTrain)\n",
    "plt.plot(range(35), listScoreTest)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.15705765407554\n"
     ]
    }
   ],
   "source": [
    "decisionTreePartut = dtree.DecisionTreeClassifier(Xtrain, Ytrain, 18)\n",
    "tree = decisionTreePartut.fit()\n",
    "print(decisionTreePartut.modelScore(tree, Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"<s>\", \"<s>\",\"J'\", \"ai\", \"la\", \"peur\", \"des\", \"long\", \"mot\", \",\", \"j'\", \"ai\", \"donc\", \"l'\", \"hippopotomonstrosesquippedaliophobie\",\"</s>\", \"</s>\"]\n",
    "\n",
    "print(len(sentence))\n",
    "\n",
    "feature = [dtree.extract_features(sentence, i, transform=hash)\n",
    "              for i in range(2, len(sentence) - 2)]\n",
    "\n",
    "print(len(feature))\n",
    "\n",
    "print(decisionTreePartut.predict(bestTree, feature))\n",
    "\n",
    "\n",
    "sentence2 = [\"<s>\", \"<s>\", \"un\", \"gâteau\", \"aux\", \"carottes\", \"est\", \"avant\", \"tout\", \"composé\", \"de\", \"carottes\", \"</s>\", \"</s>\"]\n",
    "\n",
    "feature = [dtree.extract_features(sentence2, i, transform=hash)\n",
    "              for i in range(2, len(sentence2) - 2)]\n",
    "\n",
    "print(decisionTreePartut.predict(bestTree, feature))\n",
    "\n",
    "sentence3 = [\"<s>\", \"<s>\", \"je\", \"pense\", \"donc\", \"je\", \"suis\", \",\", \"comme\", \"disait\", \"le\", \"philosophe\", \",\", \"mais\", \"peut\", \"-\", \"on\", \"considérer\", \"la\", \"réciproque\", \"de\", \"cet\", \"énoncé\", \"?\", \"</s>\", \"</s>\"]\n",
    "\n",
    "feature = [dtree.extract_features(sentence3, i, transform=hash)\n",
    "              for i in range(2, len(sentence3) - 2)]\n",
    "\n",
    "print(decisionTreePartut.predict(bestTree, feature))\n",
    "\n",
    "\n",
    "sentence4 = [\"<s>\", \"<s>\",\"il\", \"ferme\", \"la\", \"porte\", \"</s>\", \"</s>\"]\n",
    "\n",
    "feature = [dtree.extract_features(sentence4, i, transform=hash)\n",
    "              for i in range(2, len(sentence4) - 2)]\n",
    "\n",
    "print(decisionTreePartut.predict(bestTree, feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
