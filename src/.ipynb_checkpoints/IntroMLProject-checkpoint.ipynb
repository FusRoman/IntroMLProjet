{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\" align=\"center\"> Projet d'introduction au Machine Learning <br/> Out-Of-Domain PoS Tagging <br/> Présentation des résultats algorithmique</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization...\n",
      "\tPreparing corpus fr.foot.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.gsd.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.sequoia.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.ftb.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.ftb.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.spoken.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.pud.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.spoken.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.natdis.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.partut.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.sequoia.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.gsd.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.sequoia.dev.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.gsd.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.pud.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.ftb.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.partut.test.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.partut.train.json...\n",
      "\tDone\n",
      "\tPreparing corpus fr.spoken.dev.json...\n",
      "\tDone\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#chargement des corpus en mémoire\n",
    "\n",
    "import dataAnalysis as da\n",
    "import pandas as pds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pds.set_option('display.max_colwidth', -1)\n",
    "da.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistique des corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itère sur chacun des corpus\n",
    "def iterateCorpus(f, printing = True):\n",
    "    for nameCorpus, corpus in da.listeCorpus.items():\n",
    "        if printing:\n",
    "            print(\"corpus : \", nameCorpus)\n",
    "        for typeDS, dataset in corpus.getDataset().items():\n",
    "            if printing:\n",
    "                print(\"ensemble \", typeDS)\n",
    "            f(dataset, nameCorpus, typeDS)\n",
    "\n",
    "# met à jour les données statistiques\n",
    "def updateStat(dataset, nm, tds):\n",
    "    dataset.updateStat()\n",
    "\n",
    "# affiche les statistiques basique\n",
    "\n",
    "\n",
    "def printBasicStat(dataset, nm, tds):\n",
    "    #baseStat.append((nm + \" \" + tds, len(dataset.data), dataset.nbWord, dataset.nbUniqueWords))\n",
    "    print(\"   nombre de phrase : \", len(dataset.data))\n",
    "    print(\"   nombre de mot : \", dataset.nbWord)\n",
    "    print(\"   nombre de mot unique : \", dataset.nbUniqueWords)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# affiche les 10 mots / labels les plus fréquents de chaque corpus\n",
    "def printMostFrequent(dataset, nm, tds):\n",
    "    print()\n",
    "    print(\"10 mots les plus fréquents : \")\n",
    "    print(dataset.mostFrequentWord)\n",
    "    print()\n",
    "    print()\n",
    "    print(\"labels les plus fréquents : \")\n",
    "    print(dataset.mostFrequentLabel)\n",
    "    print()\n",
    "    \n",
    "# affiche les 10 mots les plus ambigu de chaque corpus\n",
    "def printMostAmbiguousWord(dataset, nm, tds):\n",
    "    ambiguousDict, ambiguousWord = dataset.ambiguousWord()\n",
    "    \n",
    "    def sortSecond(val):\n",
    "        return len(val[1])\n",
    "    \n",
    "    ambiguousWord.sort(key = sortSecond, reverse = True)\n",
    "    \n",
    "    print()\n",
    "    print(\"5 mots les plus ambigu : \", ambiguousWord[:5])\n",
    "    print()\n",
    "    \n",
    "iterateCorpus(updateStat, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseStat = []\n",
    "\n",
    "iterateCorpus(printBasicStat)\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "#print(tabulate(baseStat, tablefmt=\"latex\", floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterateCorpus(printMostFrequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mot les plus ambigu de chaque corpus\n",
    "\n",
    "iterateCorpus(printMostAmbiguousWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out Of Vocabulary Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul des Out of Vocabulary Words\n",
    "oovLatex = []\n",
    "\n",
    "\n",
    "footTest = da.listeCorpus['foot'].testDataSet\n",
    "natdisTest = da.listeCorpus['natdis'].testDataSet\n",
    "\n",
    "\n",
    "for nameCorpus, corpus in da.listeCorpus.items():\n",
    "    if corpus.trainExist:\n",
    "        oovResult = corpus.computeCorpusOOV()\n",
    "        oovResultFoot = corpus.computeOOV(footTest)\n",
    "        oovResultnatdis = corpus.computeOOV(natdisTest)\n",
    "        print(nameCorpus, \" : \")\n",
    "        print(\"     Pourcentage de l'oov entre train et test : \", oovResult[0])\n",
    "        print(\"     Pourcentage de l'oov entre train et dev : \", oovResult[1])\n",
    "        print(\"     Pourcentage de l'oov entre train et footTest : \", oovResultFoot)\n",
    "        print(\"     Pourcentage de l'oov entre train et natdisTest : \", oovResultnatdis)\n",
    "        latexRows = (nameCorpus, oovResult[0], oovResult[1], oovResultFoot, oovResultnatdis)\n",
    "        oovLatex.append(latexRows)\n",
    "\n",
    "print(tabulate(oovLatex, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divergence de Kullback-Leibler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul des divergence de KullBack-Leibler\n",
    "\n",
    "latexDKL = []\n",
    "\n",
    "for nameCorpus, corpus in da.listeCorpus.items():\n",
    "    if corpus.trainExist:\n",
    "        print(nameCorpus + \" : \")\n",
    "        DKLResult = corpus.computeCorpusKLDivergence()\n",
    "        DKLFootresult = corpus.computeKLDivergence(footTest)\n",
    "        DKLnatdisResult = corpus.computeKLDivergence(natdisTest)\n",
    "        print(\"     Dkl(test||train) = \", DKLResult)\n",
    "        print(\"     Dkl(footTest||train) = \", DKLFootresult)\n",
    "        print(\"     Dkl(natdisTest||train) = \", DKLnatdisResult)\n",
    "        latexDKL.append( (nameCorpus, DKLResult, DKLFootresult, DKLnatdisResult) )\n",
    "        \n",
    "        \n",
    "print(tabulate(latexDKL, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latexPerplexity = []\n",
    "\n",
    "print(\"                         train,                   test,              dev\")\n",
    "for nameCorpus, corpus in da.listeCorpus.items():\n",
    "    print(nameCorpus, \" : \")\n",
    "    pp_res = corpus.computePerplexityCorpus()\n",
    "    print(\"     perplexity : \", pp_res)\n",
    "    latexRow = []\n",
    "    latexRow.append(nameCorpus)\n",
    "    if type(pp_res) == tuple:\n",
    "        for i in pp_res:\n",
    "            latexRow.append(i)\n",
    "    else:\n",
    "        latexRow.append(pp_res)\n",
    "    latexPerplexity.append( latexRow )\n",
    "    \n",
    "print(tabulate(latexPerplexity, tablefmt=\"latex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modelAnalysis as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestTree, bestParam = ma.analyzeDecisionTree(\"partut\", maximum_depth=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bestParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(25733, 19)\n",
      "24930\n"
     ]
    }
   ],
   "source": [
    "import DecisionTreeClassifier as dtree\n",
    "\n",
    "trainSet, testSet = da.listeCorpus[\"partut\"].trainDataSet, da.listeCorpus[\"partut\"].testDataSet\n",
    "\n",
    "Xtrain, Ytrain = dtree.buildFeature(trainSet)\n",
    "Xtest, Ytest = dtree.buildFeature(testSet)\n",
    "\n",
    "decisionTree = dtree.DecisionTreeClassifier(Xtrain, Ytrain, max_depth=16)\n",
    "\n",
    "dt2 = dtree.DecisionTreeClassifier(Xtest, Ytest, max_depth=16)\n",
    "\n",
    "\n",
    "print(np.shape(Xtrain))\n",
    "\n",
    "print(len(Xtrain[Xtrain[:, 2] <= 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b7da5b34628c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecisionTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Informatique_et_Programmation/Intelligence Artificielle/M1_Intro_machine_learning/Projet/src/DecisionTreeClassifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredictSingleWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Informatique_et_Programmation/Intelligence Artificielle/M1_Intro_machine_learning/Projet/src/DecisionTreeClassifier.py\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(X, Y, max_depth)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# ou que l'ensemble des labels ne contient qu'un seul type de labels,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;31m# (cela signifie que l'arbre à déjà réussi à discriminer ce labels pour cette branche)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "tree = decisionTree.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreTest, cmTest = decisionTree.modelScore(tree, Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scoreTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.showConfusionMatrix(cmTest, decisionTree.classLabel.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTreePartut.showTree(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
